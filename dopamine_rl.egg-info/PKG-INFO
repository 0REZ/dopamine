Metadata-Version: 1.1
Name: dopamine-rl
Version: 0.1.12
Summary: Dopamine
Home-page: https://github.com/google/dopamine
Author: The Dopamine Team
Author-email: opensource@google.com
License: Apache 2.0
Project-URL: Source, https://github.com/google/dopamine
Project-URL: Documentation, https://github.com/google/dopamine
Project-URL: Bug Reports, https://github.com/google/dopamine/issues
Description: # Dopamine
        
        <div align="center">
          <img src="https://google.github.io/dopamine/images/dopamine_logo.png"><br><br>
        </div>
        
        Dopamine is a research framework for fast prototyping of reinforcement learning
        algorithms. It aims to fill the need for a small, easily grokked codebase in
        which users can freely experiment with wild ideas (speculative research).
        
        Our design principles are:
        
        * _Easy experimentation_: Make it easy for new users to run benchmark
                                  experiments.
        * _Flexible development_: Make it easy for new users to try out research ideas.
        * _Compact and reliable_: Provide implementations for a few, battle-tested
                                  algorithms.
        * _Reproducible_: Facilitate reproducibility in results.
        
        In the spirit of these principles, this first version focuses on supporting the
        state-of-the-art, single-GPU *Rainbow* agent ([Hessel et al., 2018][rainbow])
        applied to Atari 2600 game-playing ([Bellemare et al., 2013][ale]).
        Specifically, our Rainbow agent implements the three components identified as
        most important by [Hessel et al.][rainbow]:
        
        * n-step Bellman updates (see e.g. [Mnih et al., 2016][a3c])
        * Prioritized experience replay ([Schaul et al., 2015][prioritized_replay])
        * Distributional reinforcement learning ([C51; Bellemare et al., 2017][c51])
        
        For completeness, we also provide an implementation of DQN
        ([Mnih et al., 2015][dqn]).
        For additional details, please see our [documentation](docs/index.md).
        
        This is not an official Google product.
        
        ## Instructions
        ### Install via source
        Installing from source allows you to modify the agents and experiments as
        you please, and is likely to be the pathway of choice for long-term use.
        These instructions assume that you've already set up your favourite package
        manager (e.g. apt on Ubuntu, homebrew on Mac OS X).
        
        ```
        apt install cmake  # or brew install cmake
        pip install absl-py atari-py gin-config gym opencv-python tensorflow
        ```
        
        The entry point to the standard Atari 2600 experiment is
        [`dopamine/atari/train.py`](https://github.com/google/dopamine/blob/master/dopamine/atari/train.py).
        To run the basic DQN agent,
        
        ```
        git clone https://github.com/google/dopamine.git dopamine
        cd dopamine
        python -um dopamine.atari.train \
          --agent_name=dqn \
          --base_dir=/tmp/dopamine \
          --gin_files='dopamine/agents/dqn/configs/dqn.gin'
        ```
        
        By default, this will kick off an experiment lasting 200 million frames, with
        reasonably little output. To get finer-grained information about the process,
        you can adjust the experiment parameters in
        [`dopamine/agents/dqn/configs/dqn.gin`](https://github.com/google/dopamine/blob/master/dopamine/agents/dqn/configs/dqn.gin),
        in particular by reducing `Runner.training_steps` and `Runner.evaluation_steps`.
        More generally, the whole of Dopamine is easily configured using the
        [gin configuration framework](https://github.com/google/gin-config).
        
        ### Install as a library
        An easy, alternative way to install Dopamine is as a Python library:
        
        ```
        pip install dopamine-rl
        ```
        
        #### Running tests
        From the root directory, tests can be run with a command such as:
        
        ```
        python -um tests.agents.rainbow.rainbow_agent_test
        ```
        
        ### References
        
        [Bellemare et al., *The Arcade Learning Environment: An evaluation platform for
        general agents*. Journal of Artificial Intelligence Research, 2013.][ale]
        
        [Hessel et al., *Rainbow: Combining Improvements in Deep Reinforcement Learning*.
        Proceedings of the AAAI Conference on Artificial Intelligence, 2018.][rainbow]
        
        [Mnih et al., *Human-level control through deep reinforcement learning*. Nature,
        2015.][dqn]
        
        [Mnih et al., *Asynchronous Methods for Deep Reinforcement Learning*. Proceedings
        of the International Conference on Machine Learning, 2016.][a3c]
        
        [Schaul et al., *Prioritized Experience Replay*. Proceedings of the International
        Conference on Learning Representations, 2016.][prioritized_replay]
        
        ### Giving credit
        
        If you use Dopamine in your work, we ask that you cite this repository as a
        source. The preferred format (authors in alphabetical order) is:
        
        Marc G. Bellemare, Pablo Castro, Carles Gelada, Saurabh Kumar, Subhodeep Moitra.
        Dopamine, https://github.com/google/dopamine, 2018.
        
        
        
        [ale]: https://arxiv.org/abs/1207.4708
        [dqn]: https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf
        [a3c]: https://arxiv.org/abs/1602.01783
        [prioritized_replay]: https://arxiv.org/abs/1511.05952
        [c51]: https://arxiv.org/abs/1707.06887
        [rainbow]: https://arxiv.org/abs/1710.02298
        [iqn]: https://arxiv.org/abs/1806.06923
        
Keywords: dopamine reinforcement-learning python machine learning
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
